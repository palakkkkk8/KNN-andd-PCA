{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#KNN and PCA"
      ],
      "metadata": {
        "id": "QRki1RW5UUxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is K-Nearest Neighbors (KNN) and how does it work in both\n",
        "classification and regression problems?\n",
        "\n",
        "Ans- K-Nearest Neighbors (KNN):\n",
        "It is a supervised learning algorithm that makes predictions based on the similarity (distance) between data points.\n",
        "\n",
        "Classification: Finds the k closest neighbors and assigns the class that appears most frequently among them (majority voting).\n",
        "\n",
        "Regression: Finds the k closest neighbors and predicts the value by averaging their target values."
      ],
      "metadata": {
        "id": "bWx5RiG8Ub9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the Curse of Dimensionality and how does it affect KNN\n",
        "performance?\n",
        "\n",
        "Ans- Curse of Dimensionality:\n",
        "It refers to problems that arise when data has too many features (high dimensions).\n",
        "\n",
        "Effect on KNN:\n",
        "\n",
        "Distances between points become less meaningful (all points seem equally far).\n",
        "\n",
        "Nearest neighbors may not be truly \"close.\"\n",
        "\n",
        "Leads to poor accuracy, high computation, and overfitting."
      ],
      "metadata": {
        "id": "Gn1Qv8SLU0tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is Principal Component Analysis (PCA)? How is it different from\n",
        "feature selection?\n",
        "\n",
        "Ans- Principal Component Analysis (PCA):\n",
        "It is a dimensionality reduction technique that transforms original features into a smaller set of new, uncorrelated features (called principal components) that capture maximum variance in the data.\n",
        "\n",
        "Difference from Feature Selection:\n",
        "\n",
        "PCA: Creates new features by combining existing ones (feature transformation).\n",
        "\n",
        "Feature Selection: Keeps only the most important original features, discarding the rest."
      ],
      "metadata": {
        "id": "-2ctVzsRU8gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What are eigenvalues and eigenvectors in PCA, and why are they\n",
        "important?\n",
        "\n",
        "Ans- Eigenvalues and Eigenvectors in PCA:\n",
        "\n",
        "Eigenvectors: Directions (axes) along which the data varies the most → define the principal components.\n",
        "\n",
        "Eigenvalues: Magnitude of variance captured by each eigenvector → tell how important each component is.\n",
        "\n",
        "Importance:\n",
        "\n",
        "Eigenvectors = new feature directions.\n",
        "\n",
        "Eigenvalues = decide how much variance each direction explains → used to rank/select components."
      ],
      "metadata": {
        "id": "va26riSbVFnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.  How do KNN and PCA complement each other when applied in a single\n",
        "pipeline?\n",
        "\n",
        "Ans- KNN + PCA in a pipeline:\n",
        "\n",
        "PCA reduces dimensionality, removes noise, and keeps only the most informative features.\n",
        "\n",
        "KNN then works better because distances between points become more meaningful in lower dimensions."
      ],
      "metadata": {
        "id": "9RBqk78aVPRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train a KNN Classifier on the Wine dataset with and without feature\n",
        "scaling. Compare model accuracy in both cases."
      ],
      "metadata": {
        "id": "21Ty6lVfVYYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- KNN Without Scaling ---\n",
        "knn_no_scaling = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = knn_no_scaling.predict(X_test)\n",
        "acc_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# --- KNN With Scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaling = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = knn_scaling.predict(X_test_scaled)\n",
        "acc_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "# Print results\n",
        "print(\"KNN Accuracy without Scaling:\", acc_no_scaling)\n",
        "print(\"KNN Accuracy with Scaling:\", acc_scaling)\n",
        "\n",
        "# Plot comparison\n",
        "methods = [\"Without Scaling\", \"With Scaling\"]\n",
        "accuracies = [acc_no_scaling, acc_scaling]\n",
        "\n",
        "plt.bar(methods, accuracies, color=[\"red\", \"green\"])\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"KNN Accuracy on Wine Dataset (With vs Without Scaling)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "6q3IKaS_V4NQ",
        "outputId": "3b3b09ea-b65d-4586-d01f-7752ba69c5f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy without Scaling: 0.8055555555555556\n",
            "KNN Accuracy with Scaling: 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. : Train a PCA model on the Wine dataset and print the explained variance\n",
        "ratio of each principal component."
      ],
      "metadata": {
        "id": "Qf7cLvdNWAGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Apply PCA (keep all components)\n",
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "\n",
        "# Print explained variance ratio\n",
        "print(\"Explained Variance Ratio of each Principal Component:\")\n",
        "print(pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPguxJvYWJCu",
        "outputId": "3d3c01cd-ac4d-4dcc-fcc8-d2b63509afa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio of each Principal Component:\n",
            "[9.98091230e-01 1.73591562e-03 9.49589576e-05 5.02173562e-05\n",
            " 1.23636847e-05 8.46213034e-06 2.80681456e-06 1.52308053e-06\n",
            " 1.12783044e-06 7.21415811e-07 3.78060267e-07 2.12013755e-07\n",
            " 8.25392788e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  Train a KNN Classifier on the PCA-transformed dataset (retain top 2\n",
        "components). Compare the accuracy with the original dataset.\n"
      ],
      "metadata": {
        "id": "pKe3sFYtWNwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- KNN on Original Dataset (with scaling) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_original = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_original.fit(X_train_scaled, y_train)\n",
        "acc_original = accuracy_score(y_test, knn_original.predict(X_test_scaled))\n",
        "\n",
        "# --- PCA Transformation (retain top 2 components) ---\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "acc_pca = accuracy_score(y_test, knn_pca.predict(X_test_pca))\n",
        "\n",
        "# Print results\n",
        "print(\"KNN Accuracy on Original Dataset (scaled):\", acc_original)\n",
        "print(\"KNN Accuracy on PCA-transformed Dataset (2 components):\", acc_pca)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NR51eJTWh1d",
        "outputId": "71e63954-89d5-444d-ca9c-01f353c47f3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy on Original Dataset (scaled): 0.9722222222222222\n",
            "KNN Accuracy on PCA-transformed Dataset (2 components): 0.9166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  Train a KNN Classifier with different distance metrics (euclidean,\n",
        "manhattan) on the scaled Wine dataset and compare the results.\n"
      ],
      "metadata": {
        "id": "4kGHiToBWjex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- KNN with Euclidean Distance ---\n",
        "knn_euclidean = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
        "knn_euclidean.fit(X_train_scaled, y_train)\n",
        "acc_euclidean = accuracy_score(y_test, knn_euclidean.predict(X_test_scaled))\n",
        "\n",
        "# --- KNN with Manhattan Distance ---\n",
        "knn_manhattan = KNeighborsClassifier(n_neighbors=5, metric=\"manhattan\")\n",
        "knn_manhattan.fit(X_train_scaled, y_train)\n",
        "acc_manhattan = accuracy_score(y_test, knn_manhattan.predict(X_test_scaled))\n",
        "\n",
        "# Print results\n",
        "print(\"KNN Accuracy with Euclidean Distance:\", acc_euclidean)\n",
        "print(\"KNN Accuracy with Manhattan Distance:\", acc_manhattan)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFcRMsKhWv8S",
        "outputId": "6d6842ec-a31d-44b2-fd2d-7e782cabdb10"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy with Euclidean Distance: 0.9722222222222222\n",
            "KNN Accuracy with Manhattan Distance: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. : You are working with a high-dimensional gene expression dataset to\n",
        "classify patients with different types of cancer.\n",
        "Due to the large number of features and a small number of samples, traditional models\n",
        "overfit.\n",
        "Explain how you would:\n",
        "● Use PCA to reduce dimensionality\n",
        "● Decide how many components to keep\n",
        "● Use KNN for classification post-dimensionality reduction\n",
        "● Evaluate the model\n",
        "● Justify this pipeline to your stakeholders as a robust solution for real-world\n",
        "biomedical data\n",
        "\n",
        " Ans- Use PCA to remove noisy, redundant gene features and concentrate variance into fewer axes (principal components).\n",
        "Frontiers\n",
        "\n",
        "Decide components by (a) cumulative explained variance (e.g., 90–99%) or (b) use nested CV/grid search to pick n_components that gives best validation performance.\n",
        "mikulskibartosz.name\n",
        "Oxford Academic\n",
        "\n",
        "KNN after PCA: fit scaler → PCA (with chosen n_components) → KNN; KNN benefits because distances are more meaningful in lower-dim space.\n",
        "DIVA Portal\n",
        "\n",
        "Evaluate with nested CV (outer fold for performance, inner fold for hyperparameter selection) using stratified folds and metrics such as balanced accuracy / macro F1 / ROC-AUC (if binary).\n",
        "PMC\n",
        "\n",
        "Stakeholder justification: reduces overfitting, improves interpretability (scree / variance explained), reproducible selection via nested CV, and uses a well-understood, computationally efficient pipeline frequently used in genomics."
      ],
      "metadata": {
        "id": "ORxiE3qSWyyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Pipeline: scaling -> PCA -> KNN with nested CV for a high-dim gene expression dataset\n",
        "Replace the data-loading section with your real data (CSV, hdf5, scikit-learn loader, etc.)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import make_scorer, balanced_accuracy_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# -----------------------\n",
        "# 1) LOAD DATA (replace this with your loader)\n",
        "# -----------------------\n",
        "# Example: assume CSVs with samples as rows, genes as columns, and 'label' column for class\n",
        "# df = pd.read_csv(\"gene_expression.csv\")\n",
        "# X = df.drop(columns=[\"label\"]).values\n",
        "# y = df[\"label\"].values\n",
        "\n",
        "# For demonstration, here is a placeholder using sklearn's breast cancer (replace in real use)\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data   # <- replace with gene matrix (samples x genes)\n",
        "y = data.target\n",
        "\n",
        "# -----------------------\n",
        "# 2) Quick PCA exploratory step (compute explained variance to guide initial choice)\n",
        "# -----------------------\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler_tmp = StandardScaler()\n",
        "X_scaled_tmp = scaler_tmp.fit_transform(X)\n",
        "\n",
        "pca_tmp = PCA(n_components=min(X_scaled_tmp.shape[0], X_scaled_tmp.shape[1]))\n",
        "pca_tmp.fit(X_scaled_tmp)\n",
        "explained = pca_tmp.explained_variance_ratio_\n",
        "cumulative = np.cumsum(explained)\n",
        "\n",
        "# Print first few cumulative explained ratios\n",
        "print(\"Cumulative explained variance (first 20 components):\")\n",
        "for i, val in enumerate(cumulative[:20], start=1):\n",
        "    print(f\"PC{i}: {val:.4f}\")\n",
        "\n",
        "# Option A: pick n_components by threshold (e.g., 0.95)\n",
        "threshold = 0.95\n",
        "n_comp_by_threshold = int(np.searchsorted(cumulative, threshold) + 1)\n",
        "print(f\"\\nComponents to reach {threshold*100:.0f}% variance: {n_comp_by_threshold}\")\n",
        "\n",
        "# -----------------------\n",
        "# 3) Nested CV with pipeline (automated selection of n_components and KNN hyperparams)\n",
        "# -----------------------\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA()),             # n_components will be tuned\n",
        "    (\"knn\", KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "# Grid of hyperparameters\n",
        "param_grid = {\n",
        "    \"pca__n_components\": [5, 10, 20, 50],            # adapt depending on your data size\n",
        "    \"knn__n_neighbors\": [3, 5, 7, 9],\n",
        "    \"knn__metric\": [\"euclidean\", \"manhattan\"]\n",
        "}\n",
        "\n",
        "# Scoring: use balanced accuracy and macro-F1 (custom scorer for grid if needed)\n",
        "scoring = {\n",
        "    \"bal_acc\": make_scorer(balanced_accuracy_score),\n",
        "    \"macro_f1\": make_scorer(f1_score, average=\"macro\")\n",
        "}\n",
        "\n",
        "# Inner CV (for hyperparameter search)\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=scoring,\n",
        "    refit=\"bal_acc\",          # which metric to use for selecting best parameters\n",
        "    cv=inner_cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Outer CV (for honest performance estimate)\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "# Perform nested CV - this runs GridSearch inside each outer fold\n",
        "# cross_val_score will return the 'bal_acc' (since GridSearchCV refit uses that metric)\n",
        "nested_scores = cross_val_score(grid, X, y, cv=outer_cv, scoring=make_scorer(balanced_accuracy_score), n_jobs=-1)\n",
        "\n",
        "print(\"\\nNested CV balanced-accuracy scores (outer folds):\", nested_scores)\n",
        "print(\"Mean balanced-accuracy: {:.4f} ± {:.4f}\".format(nested_scores.mean(), nested_scores.std()))\n",
        "\n",
        "# -----------------------\n",
        "# 4) Fit final model on full data using best params found by GridSearchCV on entire dataset\n",
        "# -----------------------\n",
        "# Re-run GridSearch on whole dataset to get best estimator\n",
        "grid.fit(X, y)\n",
        "print(\"\\nBest params found (on full training data):\", grid.best_params_)\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Optional: show explained variance of selected n_components\n",
        "if hasattr(best_model.named_steps[\"pca\"], \"explained_variance_ratio_\"):\n",
        "    evr = best_model.named_steps[\"pca\"].explained_variance_ratio_\n",
        "    print(\"\\nExplained variance ratio of PCA components used:\")\n",
        "    for i, v in enumerate(evr, start=1):\n",
        "        print(f\"PC{i}: {v:.4e}\")\n",
        "\n",
        "# -----------------------\n",
        "# 5) If you have a held-out test set, evaluate final model:\n",
        "# -----------------------\n",
        "# Example (if you had X_test, y_test):\n",
        "# y_pred = best_model.predict(X_test)\n",
        "# print(classification_report(y_test, y_pred))\n",
        "# print(\"Balanced acc:\", balanced_accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP_0_astXEV7",
        "outputId": "84094fb3-88f6-40b4-db69-36f62f203297"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative explained variance (first 20 components):\n",
            "PC1: 0.4427\n",
            "PC2: 0.6324\n",
            "PC3: 0.7264\n",
            "PC4: 0.7924\n",
            "PC5: 0.8473\n",
            "PC6: 0.8876\n",
            "PC7: 0.9101\n",
            "PC8: 0.9260\n",
            "PC9: 0.9399\n",
            "PC10: 0.9516\n",
            "PC11: 0.9614\n",
            "PC12: 0.9701\n",
            "PC13: 0.9781\n",
            "PC14: 0.9834\n",
            "PC15: 0.9865\n",
            "PC16: 0.9892\n",
            "PC17: 0.9911\n",
            "PC18: 0.9929\n",
            "PC19: 0.9945\n",
            "PC20: 0.9956\n",
            "\n",
            "Components to reach 95% variance: 10\n",
            "\n",
            "Nested CV balanced-accuracy scores (outer folds): [0.95807403 0.98837209 0.96230159 0.95734127 0.95724346]\n",
            "Mean balanced-accuracy: 0.9647 ± 0.0120\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "\n",
            "Best params found (on full training data): {'knn__metric': 'euclidean', 'knn__n_neighbors': 9, 'pca__n_components': 20}\n",
            "\n",
            "Explained variance ratio of PCA components used:\n",
            "PC1: 4.4272e-01\n",
            "PC2: 1.8971e-01\n",
            "PC3: 9.3932e-02\n",
            "PC4: 6.6021e-02\n",
            "PC5: 5.4958e-02\n",
            "PC6: 4.0245e-02\n",
            "PC7: 2.2507e-02\n",
            "PC8: 1.5887e-02\n",
            "PC9: 1.3896e-02\n",
            "PC10: 1.1690e-02\n",
            "PC11: 9.7972e-03\n",
            "PC12: 8.7054e-03\n",
            "PC13: 8.0452e-03\n",
            "PC14: 5.2337e-03\n",
            "PC15: 3.1378e-03\n",
            "PC16: 2.6621e-03\n",
            "PC17: 1.9800e-03\n",
            "PC18: 1.7540e-03\n",
            "PC19: 1.6493e-03\n",
            "PC20: 1.0386e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "40 fits failed out of a total of 160.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
            "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/joblib/memory.py\", line 326, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/decomposition/_pca.py\", line 468, in fit_transform\n",
            "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
            "                                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/decomposition/_pca.py\", line 542, in _fit\n",
            "    return self._fit_full(X, n_components, xp, is_array_api_compliant)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/decomposition/_pca.py\", line 556, in _fit_full\n",
            "    raise ValueError(\n",
            "ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=30 with svd_solver='covariance_eigh'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.94359913 0.95155851 0.95765393        nan 0.94599964 0.95632042\n",
            " 0.9539199         nan 0.94371318 0.95532835 0.9530777         nan\n",
            " 0.95022499 0.95062182 0.95818106        nan 0.94598008 0.95624548\n",
            " 0.95630085        nan 0.95018587 0.95388409 0.95626505        nan\n",
            " 0.94089628 0.9539199  0.95242709        nan 0.94277649 0.95574474\n",
            " 0.95713363        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.94679704 0.95621649 0.96181696        nan 0.94872513 0.960046\n",
            " 0.95806839        nan 0.94674218 0.95992085 0.95794209        nan\n",
            " 0.95427243 0.95595817 0.96361535        nan 0.94875332 0.96007637\n",
            " 0.96001267        nan 0.9543145  0.95821557 0.9599491         nan\n",
            " 0.94307108 0.95815322 0.9596989         nan 0.94654285 0.96170377\n",
            " 0.96350655        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}